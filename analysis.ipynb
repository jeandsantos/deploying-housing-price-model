{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer,  TransformedTargetRegressor\n",
    "\n",
    "from env import *\n",
    "from plotting.plot import *\n",
    "from processing.data import Data\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = Data.from_csv(filepath=DIR_DATA_TRAIN, index_col=COL_ID)\n",
    "test  = Data.from_csv(filepath=DIR_DATA_TEST, index_col=COL_ID)\n",
    "print(train)\n",
    "repr(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more human-readable columns\n",
    "for regex, repl in REGEX_REPL_COLUMN:\n",
    "    train.columns = train.columns.map(lambda x: re.sub(string=x, pattern=regex, repl=repl))\n",
    "    test.columns = test.columns.map(lambda x: re.sub(string=x, pattern=regex, repl=repl))\n",
    "\n",
    "train.columns = train.columns.map(str.lower)\n",
    "test.columns  = test.columns.map(str.lower)\n",
    "\n",
    "train.col_target = COL_TARGET\n",
    "test.col_target = COL_TARGET\n",
    "\n",
    "print(f'Columns of training data: {train.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.print_column_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Uninformative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_columns_regex(regex='^misc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_unique(train.df, \n",
    "                  dtype_include=['float64', 'int64'],\n",
    "                  title='Count of unique values - numerical fields')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count_unique(train.df, \n",
    "                  dtype_include=['O'],\n",
    "                  title='Count of unique values - categorical fields')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.remove_constant_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate low count categorical features to 'other' category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_unique = train.count_unique(dtypes='object')\n",
    "\n",
    "CATEGORICAL_COL_COUNT_THRESHOLD = 10\n",
    "CATEGORICAL_GROUPING_THRESHOLD = 0.01\n",
    "\n",
    "for col in cat_count_unique.index[cat_count_unique > CATEGORICAL_COL_COUNT_THRESHOLD]:\n",
    "\n",
    "    # Apply grouping of categories to training set\n",
    "    cat_group_mapping = train.group_low_count_categories(col=col, fill_value='Other', threshold=CATEGORICAL_GROUPING_THRESHOLD)\n",
    "    \n",
    "    # Apply grouping of categories to test set\n",
    "    test.df[col] = test.df[col].replace(cat_group_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_missing_bool = train.df.apply(lambda x: x.isnull().sum() > 0)\n",
    "col_missing_desc = train.df.columns[col_missing_bool].tolist()\n",
    "\n",
    "print(f'Columns with missing values:')\n",
    "print(\"\\n\".join(col_missing_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    style=\"ticks\", \n",
    "    # palette=sns.color_palette(\"Set1\"), \n",
    "    rc=custom_params)\n",
    "\n",
    "# Plot percentage of missing data\n",
    "for dtypes in [['object',], ['int64', 'float64']]:\n",
    "\n",
    "    plot_perc_missing(\n",
    "        train.df, \n",
    "        title=f'% of Missing Values - {dtypes} Columns',\n",
    "        dtype_include=dtypes,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns with many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.remove_missing_columns(threshold=MISSING_THRESHOLD_DROP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create flag for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_missing_bool = train.df.apply(lambda x: x.isnull().sum() > 0)\n",
    "col_missing_desc = train.df.columns[col_missing_bool].tolist()\n",
    "\n",
    "for col in col_missing_desc:\n",
    "\n",
    "    boxplot_histogram_missingness_relationship(\n",
    "        df=train.df, \n",
    "        col_var=col, \n",
    "        col_target=train.col_target, \n",
    "        add_kde=True,\n",
    "        add_yeojohnson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.add_flag_missing_values(\n",
    "    ttest_threshold=FLAG_MISSING_PVALUE_TRESHOLD,\n",
    "    ttest_min_samples=FLAG_MISSING_MIN_SAMPLES, \n",
    "    yeojohnson_transform=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Datetime Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features from time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.create_column(\n",
    "    col_name='year_built_or_remod', \n",
    "    values=train.df[['year_remod_add', 'year_built']].apply(np.max, axis=1))\n",
    "\n",
    "def x(a,b):\n",
    "    return np.max([a-b, 0])\n",
    "\n",
    "# Calculate age when sold\n",
    "train.create_column(\n",
    "    col_name='age_garage_when_sold',\n",
    "    values=train.df.apply(lambda f: x(f['year_sold'], f['garage_year_built']), axis=1))\n",
    "\n",
    "train.create_column(\n",
    "    col_name='age_house_when_sold', \n",
    "    values=train.df.apply(lambda f: x(f['year_sold'], f['year_built_or_remod']), axis=1))\n",
    "\n",
    "train.drop_columns_regex(regex='year(?!.+missing$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms_sub_class is a categorical feature\n",
    "train.change_column_types({'ms_sub_class': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.print_column_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_cols   = [col for col in train.num_columns if len(train.df[col].unique()) < 20]\n",
    "continuous_cols = [col for col in train.num_columns if col not in discrete_cols]\n",
    "\n",
    "train.df[discrete_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship with Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in discrete_cols:\n",
    "    \n",
    "    sns.set_theme(\n",
    "            style=\"ticks\", \n",
    "            palette=sns.color_palette(\"Reds\"), \n",
    "            rc=custom_params)\n",
    "    \n",
    "    sns.catplot(data=train.df, x=col, y=COL_TARGET, kind='box', height=4.5, aspect=1.7)\n",
    "    sns.stripplot(data=train.df, x=col, y=COL_TARGET, jitter=0.1, alpha=0.1, color='k')\n",
    "    plt.title(f'Distribution of \\'{COL_TARGET}\\' by \\'{col}\\'')\n",
    "    plt.ylabel(COL_TARGET.replace('_', ' ').upper())\n",
    "    plt.xlabel(col.replace('_', ' ').upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df[continuous_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "            style=\"white\", \n",
    "            palette=sns.color_palette(\"Set2\"), \n",
    "            rc={\n",
    "                \"axes.grid\": False, \n",
    "                \"grid.color\": '0.95', \n",
    "                \"axes.spines.right\": False, \n",
    "                \"axes.spines.top\": False\n",
    "                })\n",
    "\n",
    "train.df.loc[:, continuous_cols].hist(bins=15, figsize=(15,15))\n",
    "plt.suptitle(f'Distribution of Values for Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(train.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Features with low correlation to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_correlations(train.df, col_target=train.col_target, threshold=CORRELATION_TARGET_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.remove_correlation_features(threshold=CORRELATION_TARGET_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process numerical features with high collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.remove_highly_collinear_features(threshold=COLLINEARITY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process highly correlated categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAMER_MAX_CARDINALITY = 4\n",
    "CATEGORICAL_CORRELATION_THRESHOLD = 0.80\n",
    "CATEGORICAL_CORRELATION_SELECTION_STRATEGY = 'cardinality' # 'cardinality' \n",
    "\n",
    "feats = train.remove_highly_correlated_categorical_features(\n",
    "    cramer_max_cardinality=CRAMER_MAX_CARDINALITY,\n",
    "    cramer_threshold=CATEGORICAL_CORRELATION_THRESHOLD,\n",
    "    selection_strategy=CATEGORICAL_CORRELATION_SELECTION_STRATEGY\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deployment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e405555ad3675ad80ba39828b0047efec84a170f14b23005dacf42cd0cddea8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
